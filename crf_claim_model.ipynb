{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Ap455ctLx2"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zFH44Jittzs",
        "outputId": "4f9e33bf-19f2-4de7-ed96-523807d76d89"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow_addons\n",
        "!pip install keras-crf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a0F28FXntbUA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-GLmotHGtgZN"
      },
      "outputs": [],
      "source": [
        "# BERT imports\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from transformers import BertForSequenceClassification, AutoTokenizer, AutoModelForMaskedLM\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2euDI8bYtiuY"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFvvKju0_Xja",
        "outputId": "b22c90b5-d6a9-413b-a317-783cd68a0f8b"
      },
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa\n",
        "from keras_crf import CRFModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR6pccRVtIZO"
      },
      "source": [
        "# Data Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VNaHpeMu1Yd",
        "outputId": "e5e76859-7b6d-4c6b-952d-85b7c6351220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /claim_dataset.zip, /claim_dataset.zip.zip or /claim_dataset.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# Unzip folder\n",
        "!unzip /content/drive/MyDrive/266/Data/claim_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qWqX0Tj1t7HK"
      },
      "outputs": [],
      "source": [
        "def random_undersampler(df, percent, label='target'):\n",
        "  '''Undersample class 0 to match percent subset of class 1'''\n",
        "  class_1 = df[df[label] == 1]\n",
        "  class_1_sample = class_1.sample(frac=percent, replace=False)\n",
        "  class_1_count = len(class_1_sample)\n",
        "  # Overrepresented class\n",
        "  class_0 = df[df[label] == 0]\n",
        "  class_0_sample = class_0.sample(class_1_count)\n",
        "  full_sample = pd.concat([class_0_sample, class_1_sample], axis=0)\n",
        "  return full_sample.sample(frac=1, replace=False).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CEUkGUvUuRUr"
      },
      "outputs": [],
      "source": [
        "def text_label_formatter(df, x_columns=['abstract_text'], label='target'):\n",
        "  '''Split dataframe into features/x and labels'''\n",
        "  x = pd.DataFrame()\n",
        "  for col in x_columns:\n",
        "    x[col] = df[col]\n",
        "  labels = df[label]\n",
        "  return x, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AX0QVBxIu-qa"
      },
      "outputs": [],
      "source": [
        "def explode_df(df):\n",
        "  '''Convert claim dataset into one row per sentence format'''\n",
        "  # Add sentence id to indicate order within abstract\n",
        "  sentence_ids = []\n",
        "  for label_list in df.labels:\n",
        "    sentence_ids.append(list(range(len(label_list))))\n",
        "  df['sentence_ids'] = sentence_ids\n",
        "\n",
        "  # Explode labels, sentences, and ids\n",
        "  df2 = df.explode(list(('labels','sentences', 'sentence_ids')),\n",
        "                   ignore_index=True)\n",
        "  df2['labels'] = df2['labels'].astype('int')\n",
        "  df2['sentence_ids'] = df2['sentence_ids'].astype('int')\n",
        "  return df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h70Be8_Suy4o"
      },
      "outputs": [],
      "source": [
        "# Load full json files\n",
        "cval_df_raw = pd.read_json('/content/claim_dataset/validation_labels.json', lines=True)\n",
        "ctrain_df_raw = pd.read_json('/content/claim_dataset/train_labels.json', lines=True)\n",
        "ctest_df_raw = pd.read_json('/content/claim_dataset/test_labels.json', lines=True)\n",
        "\n",
        "# Convert to single row per abstract format\n",
        "cval_df = explode_df(cval_df_raw)\n",
        "ctrain_df = explode_df(ctrain_df_raw)\n",
        "ctest_df = explode_df(ctest_df_raw)\n",
        "\n",
        "## Balance training dataset -> need full abstracts\n",
        "# ctrain_balanced = random_undersampler(ctrain_df, 1, 'labels')\n",
        "\n",
        "# Prepare data for embedding dataloader\n",
        "ctrain_texts, ctrain_labels = text_label_formatter(ctrain_df,\n",
        "                                                 ['sentences', 'paper_id', 'sentence_ids'], 'labels')\n",
        "cval_texts, cval_labels = text_label_formatter(cval_df,\n",
        "                                                 ['sentences', 'paper_id', 'sentence_ids'], 'labels')\n",
        "ctest_texts, ctest_labels = text_label_formatter(ctest_df,\n",
        "                                                 ['sentences', 'paper_id', 'sentence_ids'], 'labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI_Ris7ltccX"
      },
      "source": [
        "# Model Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8iLpcBtw6MR"
      },
      "source": [
        "## For BERT Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-YMacDuMtUVM"
      },
      "outputs": [],
      "source": [
        "# Define model ID\n",
        "model_id = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4yRmpXh7yHw3"
      },
      "outputs": [],
      "source": [
        "# Set Random seeds\n",
        "seed_val = 17\n",
        "random.seed(seed_val) ## Is this the only time I use random\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val) ## Do I need these, this is for pytorch\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alu3V2DLyfSY"
      },
      "source": [
        "### Dataloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PDtjX5_Txx0y"
      },
      "outputs": [],
      "source": [
        "# Initialize encoder\n",
        "max_length = 256\n",
        "batch_size = 3\n",
        "tokenizer = BertTokenizer.from_pretrained(model_id, \n",
        "                                          do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AKXq8kkmyicJ"
      },
      "outputs": [],
      "source": [
        "## Load training data\n",
        "# Encode\n",
        "encoded_ctrain = tokenizer.batch_encode_plus(\n",
        "    ctrain_texts['sentences'].values,\n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True,\n",
        "    truncation=True, \n",
        "    padding='max_length', \n",
        "    max_length=max_length, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Split inputs into tensors\n",
        "input_ids_ctrain = encoded_ctrain['input_ids']\n",
        "attention_masks_ctrain = encoded_ctrain['attention_mask']\n",
        "paper_id_ctrain = torch.tensor(ctrain_texts['paper_id'])\n",
        "sentence_id_ctrain = torch.tensor(ctrain_texts['sentence_ids'])\n",
        "labels_ctrain = torch.tensor(ctrain_labels.values)\n",
        "\n",
        "# Make dataset\n",
        "dataset_ctrain = TensorDataset(input_ids_ctrain, attention_masks_ctrain,\n",
        "                               labels_ctrain, paper_id_ctrain,\n",
        "                               sentence_id_ctrain)\n",
        "\n",
        "# Make dataloader\n",
        "dataloader_ctrain = DataLoader(dataset_ctrain, \n",
        "                              sampler=RandomSampler(dataset_ctrain), \n",
        "                              batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Eg2tW93tzMQS"
      },
      "outputs": [],
      "source": [
        "## Load testing data\n",
        "# Encode\n",
        "encoded_cval = tokenizer.batch_encode_plus(\n",
        "    cval_texts['sentences'].values,\n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True,\n",
        "    truncation=True, \n",
        "    padding='max_length', \n",
        "    max_length=max_length, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Split inputs into tensors\n",
        "input_ids_cval = encoded_cval['input_ids']\n",
        "attention_masks_cval = encoded_cval['attention_mask']\n",
        "paper_id_cval = torch.tensor(cval_texts['paper_id'])\n",
        "sentence_id_cval = torch.tensor(cval_texts['sentence_ids'])\n",
        "labels_cval = torch.tensor(cval_labels.values)\n",
        "\n",
        "# Make dataset\n",
        "dataset_cval = TensorDataset(input_ids_cval, attention_masks_cval, labels_cval,\n",
        "                             paper_id_cval, sentence_id_cval)\n",
        "\n",
        "# Make dataloader\n",
        "dataloader_cval = DataLoader(dataset_cval, \n",
        "                                   sampler=SequentialSampler(dataset_cval), \n",
        "                                   batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ntsEWLx1zVQP"
      },
      "outputs": [],
      "source": [
        "## Load testing data\n",
        "# Encode\n",
        "encoded_ctest = tokenizer.batch_encode_plus(\n",
        "    ctest_texts['sentences'].values,\n",
        "    add_special_tokens=True, \n",
        "    return_attention_mask=True,\n",
        "    truncation=True, \n",
        "    padding='max_length', \n",
        "    max_length=max_length, \n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Make tensors\n",
        "input_ids_ctest = encoded_ctest['input_ids']\n",
        "attention_masks_ctest = encoded_ctest['attention_mask']\n",
        "paper_id_ctest = torch.tensor(ctest_texts['paper_id'])\n",
        "sentence_id_ctest = torch.tensor(ctest_texts['sentence_ids'])\n",
        "labels_ctest = torch.tensor(ctest_labels.values)\n",
        "\n",
        "# Make dataset\n",
        "dataset_ctest = TensorDataset(input_ids_ctest, attention_masks_ctest,\n",
        "                              labels_ctest, paper_id_ctest, sentence_id_ctest)\n",
        "# Make dataloader\n",
        "dataloader_ctest = DataLoader(dataset_ctest, \n",
        "                              sampler=RandomSampler(dataset_ctest), \n",
        "                              batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPGCuBpn1kPW"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "f2WfhF5i1mB5"
      },
      "outputs": [],
      "source": [
        "## Definitions for embeddings section\n",
        "\n",
        "def get_embeddings(dataloader):\n",
        "  '''Returns Sentence Ids, Paper Ids, and Associated Hidden States'''\n",
        "  bert_model.eval()\n",
        "\n",
        "  last_hidden_states, paper_ids, sentence_ids, true_vals, preds = [],[],[],[],[]\n",
        "  for batch in dataloader:\n",
        "    batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "    # Store abstract paper id\n",
        "    paper_id = batch[3].cpu().numpy()\n",
        "    paper_ids.append(paper_id)\n",
        "\n",
        "    # Store sentence IDs\n",
        "    sentence_id = batch[4].cpu().numpy()\n",
        "    sentence_ids.append(sentence_id)\n",
        "    \n",
        "    # Store BERT inputs\n",
        "    inputs = {'input_ids':      batch[0],\n",
        "              'attention_mask': batch[1],\n",
        "              'labels':         batch[2],\n",
        "              }\n",
        "\n",
        "    # Store labels\n",
        "    label_ids = inputs['labels'].cpu().numpy()\n",
        "    true_vals.append(label_ids)\n",
        "\n",
        "    # Get BERT outputs\n",
        "    with torch.no_grad():        \n",
        "        outputs = bert_model(**inputs)\n",
        "\n",
        "    # Store hidden states\n",
        "    hidden_states = outputs[2]\n",
        "    pooled_output = torch.cat(tuple([hidden_states[i] for i in [-4, -3, -2, 1]]), dim=-1)\n",
        "    pooled_output = pooled_output[:,0,:]\n",
        "    last_hidden_state = pooled_output.detach().cpu().numpy()\n",
        "    last_hidden_states.append(last_hidden_state)\n",
        "\n",
        "    # Store logits\n",
        "    logits = outputs[1].detach().cpu().numpy()\n",
        "    preds.append(logits)\n",
        "\n",
        "  sentence_ids = np.concatenate(sentence_ids, axis=0)\n",
        "  paper_ids = np.concatenate(paper_ids, axis=0)\n",
        "  true_vals = np.concatenate(true_vals, axis=0)\n",
        "  last_hidden_states = np.concatenate(last_hidden_states, axis=0)\n",
        "  predictions = np.concatenate(preds, axis=0)\n",
        "\n",
        "  return paper_ids, sentence_ids, last_hidden_states, true_vals, predictions\n",
        "\n",
        "# Convert embeddings to dataframe for sorting\n",
        "def convert_embeddings_df(p_id, s_id, hidden_states, labels, preds):\n",
        "  '''Take embedding outputs from Dataloader/BERT, convert to dataframe and sort\n",
        "     Arrange abstracts into order, regardless of dataloading shuffling'''\n",
        "  a = []\n",
        "  for (p_id, s_id, hidden, label, pred) in zip(p_id, s_id, hidden_states, labels, preds):\n",
        "    a.append([p_id, s_id, hidden, label, pred])\n",
        "  df = pd.DataFrame(a, columns=['paper_ids', 'sentence_ids', 'hidden_states',\n",
        "                                'labels', 'predictions'])\n",
        "  df.sort_values(by=['paper_ids', 'sentence_ids'], inplace=True)\n",
        "  return df\n",
        "\n",
        "# Convert embedding dataframe into lists\n",
        "def get_hiddenstate_tensor(df, unique_p_ids):\n",
        "  '''Get hidden state tensors from dataframe grouped by paper, in order of sentence\n",
        "     Final tensor should be in shape (batch size, sequence length, hidden_state size)'''\n",
        "  hidden_states = []\n",
        "  for paper_id in unique_p_ids:\n",
        "    batch_hidden_state = []\n",
        "    # Get Hidden States\n",
        "    for hidden_state in df[df['paper_ids'] == paper_id]['hidden_states']:\n",
        "      batch_hidden_state.append(hidden_state)\n",
        "    # Pad to Seq Length 10\n",
        "    for i in range(10):\n",
        "      try:\n",
        "        batch_hidden_state[i]\n",
        "      except:\n",
        "        batch_hidden_state.append(np.zeros(batch_hidden_state[i-1].size)) ## Check this\n",
        "    hidden_states.append(batch_hidden_state)\n",
        "  return tf.convert_to_tensor(hidden_states)\n",
        "\n",
        "def get_prediction_tensor(df, unique_p_ids):\n",
        "  '''Get prediction logits from BERT output, grouped as a list by paper in order of sentence\n",
        "     Final tensor should be shape (batch size, sequence length, num_classes)'''\n",
        "  predictions = []\n",
        "  for paper_id in unique_p_ids:\n",
        "    batch_prediction = []\n",
        "    for prediction in df[df['paper_ids'] == paper_id]['predictions']:\n",
        "      batch_prediction.append(prediction)\n",
        "    # Pad to Seq Length 10\n",
        "    for i in range(10):\n",
        "      try:\n",
        "        batch_prediction[i]\n",
        "      except:\n",
        "        batch_prediction.append(np.array([0,0]))\n",
        "    predictions.append(batch_prediction)\n",
        "  return tf.convert_to_tensor(predictions)\n",
        "\n",
        "def get_label_tensor(df, unique_p_ids):\n",
        "  '''Get true labels from dataloader, grouped as a list by paper in order of sentence\n",
        "    Final tensor should be shape (batch size, sequence length)'''\n",
        "  labels = []\n",
        "  for paper_id in unique_p_ids:\n",
        "    batch_label = []\n",
        "    for label in df[df['paper_ids'] == paper_id]['labels']:\n",
        "      batch_label.append(label)\n",
        "    # Pad to Seq Length 10 with mask indicator -1\n",
        "    batch_label = (batch_label + 10*[-1])[:10]\n",
        "    labels.append(batch_label)\n",
        "  labels = tf.convert_to_tensor(labels)\n",
        "  return tf.cast(labels, tf.float32)\n",
        "\n",
        "def get_mask_tensor(df, unique_p_ids):\n",
        "  '''Get mask from dataloader for each abstract, list of 1 (not masked) and 0s (masked)\n",
        "    Final tensor should be shape (batch size, sequence length)'''\n",
        "  masks = []\n",
        "  for paper_id in unique_p_ids:\n",
        "    batch_mask = []\n",
        "    for label in df[df['paper_ids'] == paper_id]['labels']:\n",
        "      batch_mask.append(1)\n",
        "    batch_mask = (batch_mask + 10*[0])[:10]\n",
        "    masks.append(batch_mask)\n",
        "  return tf.convert_to_tensor(masks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9-Yyw9fxu4z",
        "outputId": "f6c8b585-eb49-4553-e061-f9fc1e153985"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set BERT parameters\n",
        "num_labels = 2\n",
        "\n",
        "# Initialize Bert Model\n",
        "bert_model = BertForSequenceClassification.from_pretrained(model_id,\n",
        "                                                      num_labels=num_labels,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=True)\n",
        "\n",
        "# Load fine tuned model weights\n",
        "bert_model.load_state_dict(torch.load(\n",
        "                          '/content/drive/MyDrive/266/BERT_Fine_Tuning/claim_F1886.model',\n",
        "                          map_location=torch.device('cpu')))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "bert_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMJgwCmr-L3l",
        "outputId": "287fb5a6-b9e1-4dd2-ab36-81571ccb31e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature shape:  (750, 10, 3072)\n",
            "BERT Predictions shape:  (750, 10, 2)\n",
            "Label shape:  (750, 10)\n",
            "Mask shape:  (750, 10)\n"
          ]
        }
      ],
      "source": [
        "# Training Embeddings\n",
        "df_ctrain = convert_embeddings_df(*get_embeddings(dataloader_ctrain))\n",
        "\n",
        "ctrain_unique = df_ctrain['paper_ids'].unique()\n",
        "ctrain_x = get_hiddenstate_tensor(df_ctrain, ctrain_unique)\n",
        "print(\"Feature shape: \", ctrain_x.shape)\n",
        "ctrain_predictions = get_prediction_tensor(df_ctrain, ctrain_unique)\n",
        "print(\"BERT Predictions shape: \", ctrain_predictions.shape)\n",
        "ctrain_y = get_label_tensor(df_ctrain, ctrain_unique)\n",
        "print(\"Label shape: \", ctrain_y.shape)\n",
        "ctrain_masks = get_mask_tensor(df_ctrain, ctrain_unique)\n",
        "print(\"Mask shape: \", ctrain_masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGGkOwEErL_T",
        "outputId": "f66b272a-b06b-4ef3-8486-a8015c231759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature shape:  (375, 10, 3072)\n",
            "BERT Predictions shape:  (375, 10, 2)\n",
            "Label shape:  (375, 10)\n",
            "Mask shape:  (375, 10)\n"
          ]
        }
      ],
      "source": [
        "# Validation Embeddings\n",
        "df_cval = convert_embeddings_df(*get_embeddings(dataloader_cval))\n",
        "\n",
        "cval_unique = df_cval['paper_ids'].unique()\n",
        "cval_x = get_hiddenstate_tensor(df_cval, cval_unique)\n",
        "print(\"Feature shape: \", cval_x.shape)\n",
        "cval_predictions = get_prediction_tensor(df_cval, cval_unique)\n",
        "print(\"BERT Predictions shape: \", cval_predictions.shape)\n",
        "cval_y = get_label_tensor(df_cval, cval_unique)\n",
        "print(\"Label shape: \", cval_y.shape)\n",
        "cval_masks = get_mask_tensor(df_cval, cval_unique)\n",
        "print(\"Mask shape: \", cval_masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaS9jk6QK5XC",
        "outputId": "10b03bc5-a54d-41cf-97ce-32e7d9c53b55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature shape:  (375, 10, 3072)\n",
            "BERT Predictions shape:  (375, 10, 2)\n",
            "Label shape:  (375, 10)\n",
            "Mask shape:  (375, 10)\n"
          ]
        }
      ],
      "source": [
        "# Test Embeddings\n",
        "df_ctest = convert_embeddings_df(*get_embeddings(dataloader_ctest))\n",
        "\n",
        "ctest_unique = df_ctest['paper_ids'].unique()\n",
        "ctest_x = get_hiddenstate_tensor(df_ctest, ctest_unique)\n",
        "print(\"Feature shape: \", ctest_x.shape)\n",
        "ctest_predictions = get_prediction_tensor(df_ctest, ctest_unique)\n",
        "print(\"BERT Predictions shape: \", ctest_predictions.shape)\n",
        "ctest_y = get_label_tensor(df_ctest, ctest_unique)\n",
        "print(\"Label shape: \", ctest_y.shape)\n",
        "ctest_masks = get_mask_tensor(df_ctest, ctest_unique)\n",
        "print(\"Mask shape: \", ctest_masks.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd46MV5x_dGS"
      },
      "source": [
        "## Create CRF Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "M9joUeRkp7bS"
      },
      "outputs": [],
      "source": [
        "# Define function to determine accuracy from masked inputs\n",
        "def crf_accuracy(y_true, y_pred):\n",
        "  '''Calculate accuracy without masked inputs'''\n",
        "  correct = np.sum(y_pred[0] == y_true)\n",
        "  total = np.sum(y_true != -1)\n",
        "  return correct / total\n",
        "\n",
        "def crf_precision(y_true, y_pred):\n",
        "  '''Calculate precision without masked inputs'''\n",
        "  tp = np.sum((y_pred[0]==1) & (y_true==1))\n",
        "  fp = np.sum((y_pred[0]==1) & (y_true==0))\n",
        "  return tp / (fp + tp)\n",
        "\n",
        "def crf_recall(y_true, y_pred):\n",
        "  tp = np.sum((y_pred[0]==1) & (y_true==1))\n",
        "  fn = np.sum((y_pred[0]==0) & (y_true==1))\n",
        "  return tp / (tp+fn)\n",
        "\n",
        "def crf_confusion_matrix(y_true, y_pred):\n",
        "  tp = np.sum((y_pred[0]==1) & (y_true==1))\n",
        "  fp = np.sum((y_pred[0]==1) & (y_true==0))\n",
        "  tn = np.sum((y_pred[0]==0) & (y_true==0))\n",
        "  fn = np.sum((y_pred[0]==0) & (y_true==1))\n",
        "  return [[tp, fp], [fn, tn]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "QKKx7AeegQLL"
      },
      "outputs": [],
      "source": [
        "# Define Base model\n",
        "inputs = tf.keras.Input(shape=(None, 3072))\n",
        "mask = mask = tf.keras.layers.Masking(mask_value=0)(inputs)\n",
        "x = tf.keras.layers.Dense(786, activation='relu')(mask)\n",
        "dropout = tf.keras.layers.Dropout(0.1)(x)\n",
        "outputs = tf.keras.layers.Dense(786, activation='relu')(dropout)\n",
        "base_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Wrap base model to add CRF layer and \n",
        "crf_model = CRFModel(base_model, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL663gwShhdb",
        "outputId": "4254210d-bd12-47a0-f7cb-786ebe9aa45d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"crf_model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)          [(None, None, 3072)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " masking_9 (Masking)            (None, None, 3072)   0           ['input_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_37 (Dense)               (None, None, 786)    2415378     ['masking_9[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, None, 786)    0           ['dense_37[0][0]']               \n",
            "                                                                                                  \n",
            " dense_38 (Dense)               (None, None, 786)    618582      ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " crf_10 (CRF)                   [(None, None),       1582        ['dense_38[0][0]']               \n",
            "                                 (None, None, 2),                                                 \n",
            "                                 (None,),                                                         \n",
            "                                 (2, 2)]                                                          \n",
            "                                                                                                  \n",
            " decode_sequence (Lambda)       (None, None)         0           ['crf_10[0][0]']                 \n",
            "                                                                                                  \n",
            " potentials (Lambda)            (None, None, 2)      0           ['crf_10[0][1]']                 \n",
            "                                                                                                  \n",
            " sequence_length (Lambda)       (None,)              0           ['crf_10[0][2]']                 \n",
            "                                                                                                  \n",
            " kernel (Lambda)                (2, 2)               0           ['crf_10[0][3]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,035,542\n",
            "Trainable params: 3,035,542\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Compile model\n",
        "lr = 1e-4\n",
        "crf_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr))\n",
        "crf_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GLukiP2hpJl",
        "outputId": "c8020448-7c2e-4979-e648-1edb1b4ef479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 9s 139ms/step - loss: 1.3704 - val_loss: 1.2353\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 2s 65ms/step - loss: 1.1789 - val_loss: 1.1271\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 1s 47ms/step - loss: 1.1274 - val_loss: 1.1225\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.0098 - val_loss: 1.1917\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 1.0087 - val_loss: 1.1927\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.9476 - val_loss: 1.1578\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 1.0057 - val_loss: 1.3385\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.8749 - val_loss: 1.3813\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.8945 - val_loss: 1.4236\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.8099 - val_loss: 1.4980\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a177473a0>"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train model\n",
        "crf_model.fit(x=ctrain_x, y=ctrain_y, validation_data=(cval_x, cval_y),epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqosWE9Xh45E",
        "outputId": "772539e0-854d-4768-c92e-d2c19d334eab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 1s 53ms/step\n",
            "Accuracy is:  0.9327902240325866\n",
            "Precision is:  0.856353591160221\n",
            "Recall is:  0.7948717948717948\n",
            "CM is:  [[465, 78], [120, 2283]]\n"
          ]
        }
      ],
      "source": [
        "# Get validation scores\n",
        "val_scores = crf_model.predict(cval_x)\n",
        "val_acc = crf_accuracy(cval_y, val_scores)\n",
        "print(\"Accuracy is: \",val_acc)\n",
        "val_precision = crf_precision(cval_y, val_scores)\n",
        "print(\"Precision is: \",val_precision)\n",
        "val_recall = crf_recall(cval_y, val_scores)\n",
        "print(\"Recall is: \",val_recall)\n",
        "val_cm = crf_confusion_matrix(cval_y, val_scores)\n",
        "print(\"CM is: \",val_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_hrQSz5lG75",
        "outputId": "ea6154bd-dbda-4c91-ade9-76393d2dd4e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 1s 44ms/step\n",
            "Accuracy is:  0.9249914763041255\n",
            "Precision is:  0.8574338085539714\n",
            "Recall is:  0.7373029772329247\n",
            "CM is:  [[421, 70], [150, 2292]]\n"
          ]
        }
      ],
      "source": [
        "# Get Test Scores\n",
        "test_scores = crf_model.predict(ctest_x)\n",
        "test_acc = crf_accuracy(ctest_y, test_scores)\n",
        "print(\"Accuracy is: \",test_acc)\n",
        "test_precision = crf_precision(ctest_y, test_scores)\n",
        "print(\"Precision is: \",test_precision)\n",
        "test_recall = crf_recall(ctest_y, test_scores)\n",
        "print(\"Recall is: \",test_recall)\n",
        "test_cm = crf_confusion_matrix(ctest_y, test_scores)\n",
        "print(\"CM is: \",test_cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsawpIe24qF_",
        "outputId": "c27cb20d-6778-43ed-b28a-a10efc94d109"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(375, 10)"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Select value from tensor at index\n",
        "def get_value_at_index(tensor, index):\n",
        "    return tensor[index].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make list of length 100 of random 0 and 1\n",
        "labels = [random.randint(0,1) for i in range(100)]\n",
        "preds = [random.randint(0,1) for i in range(100)]\n",
        "position = [random.randint(0,9) for i in range(100)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "probability_dict = {\n",
        "    0:    0.002667,\n",
        "    1:    0.017333,\n",
        "    2:    0.049333,\n",
        "    3:    0.069333,\n",
        "    4:    0.150667,\n",
        "    5:    0.247110,\n",
        "    6:    0.386986,\n",
        "    7:    0.530374,\n",
        "    8:    0.698473,\n",
        "    9: 0.897196\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtmZ7ZdH4grb",
        "outputId": "dee9fd9c-719e-466a-d8f1-0049ea45d8a2"
      },
      "outputs": [],
      "source": [
        "# Make list of length 100 of random 0 and 1s with probability of 1s based on position\n",
        "# Position determined from position list\n",
        "preds = [random.choices([0,1], weights=[1-probability_dict[i], probability_dict[i]])[0] for i in position]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmchbOtE4yB2"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy of preds compared to labels\n",
        "accuracy = sum([1 for i in range(len(labels)) if labels[i] == preds[i]]) / len(labels)\n",
        "print(\"Accuracy is: \", accuracy)\n",
        "\n",
        "# Calculate precision of preds compared to labels\n",
        "tp = sum([1 for i in range(len(labels)) if labels[i] == 1 and preds[i] == 1])\n",
        "fp = sum([1 for i in range(len(labels)) if labels[i] == 0 and preds[i] == 1])\n",
        "precision = tp / (tp + fp)\n",
        "print(\"Precision is: \", precision)\n",
        "\n",
        "# Calculate recall of preds compared to labels\n",
        "tp = sum([1 for i in range(len(labels)) if labels[i] == 1 and preds[i] == 1])\n",
        "fn = sum([1 for i in range(len(labels)) if labels[i] == 1 and preds[i] == 0])\n",
        "recall = tp / (tp + fn)\n",
        "print(\"Recall is: \", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find accuracy of preds compared to labels, separeted by value in position list\n",
        "for i in range(10):\n",
        "    print(\"Position: \", i)\n",
        "    labels_i = [labels[j] for j in range(len(labels)) if position[j] == i]\n",
        "    preds_i = [preds[j] for j in range(len(preds)) if position[j] == i]\n",
        "    accuracy = sum([1 for j in range(len(labels_i)) if labels_i[j] == preds_i[j]]) / len(labels_i)\n",
        "    print(\"Accuracy is: \", accuracy)\n",
        "\n",
        "# Find precision of preds compared to labels, separeted by value in position list\n",
        "for i in range(10):\n",
        "    print(\"Position: \", i)\n",
        "    labels_i = [labels[j] for j in range(len(labels)) if position[j] == i]\n",
        "    preds_i = [preds[j] for j in range(len(preds)) if position[j] == i]\n",
        "    tp = sum([1 for j in range(len(labels_i)) if labels_i[j] == 1 and preds_i[j] == 1])\n",
        "    fp = sum([1 for j in range(len(labels_i)) if labels_i[j] == 0 and preds_i[j] == 1])\n",
        "    precision = tp / (tp + fp)\n",
        "    print(\"Precision is: \", precision)\n",
        "    labels_i = [labels[j] for j in range(len(labels)) if position[j] == i]\n",
        "    preds_i = [preds[j] for j in range(len(preds)) if position[j] == i]\n",
        "    tp = sum([1 for j in range(len(labels_i)) if labels_i[j] == 1 and preds_i[j] == 1])\n",
        "    fn = sum([1 for j in range(len(labels_i)) if labels_i[j] == 1 and preds_i[j] == 0])\n",
        "    recall = tp / (tp + fn)\n",
        "    print(\"Recall is: \", recall)\n",
        "    labels_i = [labels[j] for j in range(len(labels)) if position[j] == i]\n",
        "    preds_i = [preds[j] for j in range(len(preds)) if position[j] == i]\n",
        "    accuracy = sum([1 for j in range(len(labels_i)) if labels_i[j] == preds_i[j]]) / len(labels_i)\n",
        "    print(\"Accuracy is: \", accuracy)\n",
        "\n",
        "\n",
        "# Find recall of preds compared to labels, separeted by value in position list\n",
        "for i in range(10):\n",
        "    print(\"Position: \", i)\n",
        "    labels_i = [labels[j] for j in range(len(labels)) if position[j] == i]\n",
        "    preds_i = [preds[j] for j in range(len(preds)) if position[j] == i]\n",
        "    tp = sum([1 for j in range(len(labels_i)) if labels_i[j] == 1 and preds_i[j] == 1])\n",
        "    fn = sum([1 for j in range(len(labels_i)) if labels_i[j] == 1 and preds_i[j] == 0])\n",
        "    recall = tp / (tp + fn)\n",
        "    print(\"Recall is: \", recall)\n",
        "\n",
        "# Find F1 score of preds compared to labels, separeted by value in position list\n",
        "for i in range(10):\n",
        "    print(\"Position: \", i)\n",
        "    labels_i = [labels[j] for j in range(len(labels)) if position[j] == i]\n",
        "    preds_i = [preds[j] for j in range(len(preds)) if position[j] == i]\n",
        "    tp = sum([1 for j in range(len(labels_i)) if labels_i[j] == 1 and preds_i[j] == 1])\n",
        "    fp = sum([1 for j in range(len(labels_i)) if labels_i[j] == 0 and preds_i[j] == 1])\n",
        "    precision = tp / (tp + fp)\n",
        "    print(\"Precision is: \", precision)\n",
        "    labels_i = [labels[j] for j in range(len(labels)) if position[j] == i]\n",
        "    preds_i = [preds[j] for j in range(len(preds)) if position[j] == i]\n",
        "    tp = sum([1 for j in range(len(labels_i)) if labels_i[j] == 1 and preds_i[j] == 1])\n",
        "    fn = sum([1 for j in range(len(labels_i)) if labels_i[j] == 1 and preds_i[j] == 0])\n",
        "    recall = tp / (tp + fn)\n",
        "    print(\"Recall is: \", recall)\n",
        "    labels_i = [labels[j] for j in range(len(labels)) if position[j] == i]\n",
        "    preds_i = [preds[j] for j in range(len(preds)) if position[j] == i]\n",
        "    accuracy = sum([1 for j in range(len(labels_i)) if labels_i[j] == preds_i[j]]) / len(labels_i)\n",
        "    print(\"Accuracy is: \", accuracy)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    print(\"F1 is: \", f1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "position_df = pd.DataFrame(rows, columns=['position', 'n', 'positives',\n",
        "                                          'crf_accuracy', 'bert_accuracy',\n",
        "                                          'crf_precision', 'bert_precision',\n",
        "                                          'crf_recall', 'bert_recall',\n",
        "                                          'crf_cm', 'bert_cm'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add F1 score to dataframe\n",
        "position_df['crf_f1'] = 2 * (position_df['crf_precision'] * position_df['crf_recall']) / (position_df['crf_precision'] + position_df['crf_recall'])\n",
        "position_df['bert_f1'] = 2 * (position_df['bert_precision'] * position_df['bert_recall']) / (position_df['bert_precision'] + position_df['bert_recall'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build model that takes in array of (batchsize, sequence size, embedding_size)\n",
        "# And applies attention over the sequence size dimension\n",
        "class Attention(keras.layers.Layer):\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        self.return_attention = return_attention\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(name='att_weight', shape=(input_shape[-1], 1), initializer='normal')\n",
        "        self.b = self.add_weight(name='att_bias', shape=(input_shape[1], 1), initializer='zeros')\n",
        "        super(Attention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        et = K.squeeze(K.tanh(K.dot(x, self.w) + self.b), axis=-1)\n",
        "        at = K.softmax(et)\n",
        "        at = K.expand_dims(at, axis=-1)\n",
        "        output = x * at\n",
        "        output = K.sum(output, axis=1)\n",
        "        if self.return_attention:\n",
        "            return [output, at]\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], input_shape[-1]), (input_shape[0], input_shape[1])]\n",
        "        return input_shape[0], input_shape[-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'return_attention': self.return_attention,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "# Create model\n",
        "def create_model():\n",
        "    input_layer = keras.layers.Input((None, 3072))\n",
        "    lstm_layer = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(input_layer)\n",
        "    attention_layer = Attention()(lstm_layer)\n",
        "    output_layer = keras.layers.Dense(1, activation='sigmoid')(attention_layer)\n",
        "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Compile model\n",
        "model = create_model()\n",
        "model.summary()\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.1)\n",
        "\n",
        "# Evaluate model\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Keras biLSTM attention model\n",
        "def create_model():\n",
        "    input_layer = keras.layers.Input((None, 3072))\n",
        "    lstm_layer = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(input_layer)\n",
        "    attention_layer = Attention()(lstm_layer)\n",
        "    output_layer = keras.layers.Dense(1, activation='sigmoid')(attention_layer)\n",
        "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Compile model\n",
        "model = create_model()\n",
        "model.summary()\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Embedding dimension of 3072\n",
        "# Sequence of 10\n",
        "# Batch size of 32\n",
        "\n",
        "# Accept input of shape (sequence size, embedding size)\n",
        "input_layer = tf.keras.layers.Input((10, 3072))\n",
        "\n",
        "# Make empty embeddings layer in the same size as the input\n",
        "embedding_layer = tf.keras.layers.Embedding(1, 3072, input_length=10)\n",
        "\n",
        "# create keys layer\n",
        "keys = embedding_layer(input_layer)\n",
        "\n",
        "# Make attention matrices\n",
        "one_vector = tf.Variable(tf.ones((1,1,1)))\n",
        "batch_of_ones = tf.tile(one_vector, (tf.shape(input_layer)[0], 1, 1))\n",
        "query_layer = tf.keras.layers.Dense(3072, use_bias=False)\n",
        "query = query_layer(batch_of_ones)\n",
        "\n",
        "# Calculate attention\n",
        "attention_output = tf.keras.layers.Attention()([query, keys], return_attention_scores=True)\n",
        "\n",
        "# Add dense layer\n",
        "dense_layer = tf.keras.layers.Dense(1, activation='sigmoid')(attention_output[0])\n",
        "\n",
        "# Create model\n",
        "model = tf.keras.models.Model(inputs=input_layer, outputs=dense_layer)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "New section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bert Model Params\n",
        "num_labels = 2\n",
        "lr = 1e-5\n",
        "eps = 1e-8\n",
        "epochs = 12\n",
        "num_warmup_steps = 100\n",
        "fine_tuned_weights = None\n",
        "#'/content/drive/MyDrive/266/BERT_Fine_Tuning/finetuned_BERTlarge_epoch_2.model'\n",
        "\n",
        "# Initialize Bert Model\n",
        "bert_model = BertForSequenceClassification.from_pretrained(model_id,\n",
        "                                                      num_labels=num_labels,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=True)\n",
        "if fine_tuned_weights:\n",
        "  bert_model.load_state_dict(torch.load(fine_tuned_weights,\n",
        "                                        map_location=torch.device('cpu')))\n",
        "optimizer = AdamW(bert_model.parameters(),\n",
        "                  lr=lr, \n",
        "                  eps=eps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=num_warmup_steps,\n",
        "                                            num_training_steps=len(dataloader_ctrain)*epochs)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "bert_model.to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define function for BERT evaluation\n",
        "def evaluate_bert(dataloader_val):\n",
        "\n",
        "    bert_model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in dataloader_val:\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = bert_model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train BERT model\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "    bert_model.train()\n",
        "\n",
        "    loss_train_total = 0\n",
        "    best_f1 = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_ctrain, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        bert_model.zero_grad()\n",
        "\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }       \n",
        "\n",
        "        outputs = bert_model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "\n",
        "    loss_train_avg = loss_train_total/len(dataloader_ctrain)            \n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate_bert(dataloader_cval)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    accuracy = overall_accuracy(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
        "    tqdm.write(f'Accuracy: {accuracy}')\n",
        "\n",
        "    # Save best model\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        best_epoch = epoch\n",
        "        torch.save(bert_model.state_dict(),\n",
        "                   f'/content/drive/MyDrive/266/BERT_Fine_Tuning/BERTdiscourse_f1_{round(val_f1,4)}.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "best_model_path = '/content/drive/MyDrive/266/BERT_Fine_Tuning/BERTdiscourse_f1_0.9219.model'\n",
        "bert_model.load_state_dict(torch.load(best_model_path, map_location=torch.device('cpu')))\n",
        "bert_model.to(device)\n",
        "\n",
        "# Evaluate best model\n",
        "_, predictions, true_vals = evaluate_bert(dataloader_cval)\n",
        "val_f1 = f1_score_func(predictions, true_vals)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(true_vals, np.argmax(predictions, axis=1), target_names=['0', '1']))\n",
        "\n",
        "# Evaluate best model on test set\n",
        "_, predictions, true_vals = evaluate_bert(dataloader_ctest)\n",
        "val_f1 = f1_score_func(predictions, true_vals)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get accuracy, precision, recall, and f1 score from sklearn\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluate model on test set\n",
        "_, predictions, true_vals = evaluate_bert(dataloader_ctest)\n",
        "recall = recall_score(true_vals, np.argmax(predictions, axis=1), average='weighted')\n",
        "precision = precision_score(true_vals, np.argmax(predictions, axis=1), average='weighted')\n",
        "f1 = f1_score(true_vals, np.argmax(predictions, axis=1), average='weighted')\n",
        "accuracy = accuracy_score(true_vals, np.argmax(predictions, axis=1))\n",
        "\n",
        "# Print results\n",
        "print('Accuracy: {:.2f}'.format(accuracy))\n",
        "print('Precision: {:.2f}'.format(precision))\n",
        "print('Recall: {:.2f}'.format(recall))\n",
        "print('F1: {:.2f}'.format(f1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_undersampler(df, percent, label='target'):\n",
        "  '''Undersample class 0 to match percent subset of class 1'''\n",
        "  class_1 = df[df[label] == 1]\n",
        "  class_1_sample = class_1.sample(frac=percent, replace=False)\n",
        "  class_1_count = len(class_1_sample)\n",
        "  # Overrepresented class\n",
        "  class_0 = df[df[label] == 0]\n",
        "  class_0_sample = class_0.sample(class_1_count)\n",
        "  full_sample = pd.concat([class_0_sample, class_1_sample], axis=0)\n",
        "  return full_sample.sample(frac=1, replace=False).reset_index(drop=True)\n",
        "\n",
        "def random_oversampler(df, percent, label='target'):\n",
        "  '''Oversample class 1 to match percent subset of class 0'''\n",
        "    class_0 = df[df[label] == 0]\n",
        "    class_0_sample = class_0.sample(frac=percent, replace=True)\n",
        "    class_0_count = len(class_0_sample)\n",
        "    # Underrepresented class\n",
        "    class_1 = df[df[label] == 1]\n",
        "    class_1_sample = class_1.sample(class_0_count, replace=True)\n",
        "    full_sample = pd.concat([class_0_sample, class_1_sample], axis=0)\n",
        "    return full_sample.sample(frac=1, replace=False).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make dataframe with one column, consisting of lists of dimension 2 of random floats\n",
        "df = pd.DataFrame(np.random.rand(100,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine columns into a third column list\n",
        "df['combined'] = df.apply(lambda x: [x[0], x[1]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>combined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.294665</td>\n",
              "      <td>0.530587</td>\n",
              "      <td>[0.2946650026871097, 0.5305867556052941]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.191521</td>\n",
              "      <td>0.067900</td>\n",
              "      <td>[0.19152078694749486, 0.06790035819129137]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.786985</td>\n",
              "      <td>0.656334</td>\n",
              "      <td>[0.7869854599999133, 0.6563335217758555]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.637521</td>\n",
              "      <td>0.575603</td>\n",
              "      <td>[0.6375208960436358, 0.575602893753034]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.039063</td>\n",
              "      <td>0.357814</td>\n",
              "      <td>[0.03906291618886648, 0.35781360448354893]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.913303</td>\n",
              "      <td>0.590220</td>\n",
              "      <td>[0.9133029199647259, 0.5902203718852678]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.171194</td>\n",
              "      <td>0.714474</td>\n",
              "      <td>[0.17119434728109106, 0.714474477740643]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.238446</td>\n",
              "      <td>0.921805</td>\n",
              "      <td>[0.23844605886430326, 0.9218051432493948]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.721274</td>\n",
              "      <td>0.676923</td>\n",
              "      <td>[0.7212738667495618, 0.6769229790876689]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.986811</td>\n",
              "      <td>0.539745</td>\n",
              "      <td>[0.9868105563430492, 0.5397451964974905]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1                                    combined\n",
              "0   0.294665  0.530587    [0.2946650026871097, 0.5305867556052941]\n",
              "1   0.191521  0.067900  [0.19152078694749486, 0.06790035819129137]\n",
              "2   0.786985  0.656334    [0.7869854599999133, 0.6563335217758555]\n",
              "3   0.637521  0.575603     [0.6375208960436358, 0.575602893753034]\n",
              "4   0.039063  0.357814  [0.03906291618886648, 0.35781360448354893]\n",
              "..       ...       ...                                         ...\n",
              "95  0.913303  0.590220    [0.9133029199647259, 0.5902203718852678]\n",
              "96  0.171194  0.714474    [0.17119434728109106, 0.714474477740643]\n",
              "97  0.238446  0.921805   [0.23844605886430326, 0.9218051432493948]\n",
              "98  0.721274  0.676923    [0.7212738667495618, 0.6769229790876689]\n",
              "99  0.986811  0.539745    [0.9868105563430492, 0.5397451964974905]\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select the index of the largest value in the combined column\n",
        "df['max_index'] = df['combined'].apply(lambda x: np.argmax(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>combined</th>\n",
              "      <th>max_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.294665</td>\n",
              "      <td>0.530587</td>\n",
              "      <td>[0.2946650026871097, 0.5305867556052941]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.191521</td>\n",
              "      <td>0.067900</td>\n",
              "      <td>[0.19152078694749486, 0.06790035819129137]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.786985</td>\n",
              "      <td>0.656334</td>\n",
              "      <td>[0.7869854599999133, 0.6563335217758555]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.637521</td>\n",
              "      <td>0.575603</td>\n",
              "      <td>[0.6375208960436358, 0.575602893753034]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.039063</td>\n",
              "      <td>0.357814</td>\n",
              "      <td>[0.03906291618886648, 0.35781360448354893]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.913303</td>\n",
              "      <td>0.590220</td>\n",
              "      <td>[0.9133029199647259, 0.5902203718852678]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.171194</td>\n",
              "      <td>0.714474</td>\n",
              "      <td>[0.17119434728109106, 0.714474477740643]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.238446</td>\n",
              "      <td>0.921805</td>\n",
              "      <td>[0.23844605886430326, 0.9218051432493948]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.721274</td>\n",
              "      <td>0.676923</td>\n",
              "      <td>[0.7212738667495618, 0.6769229790876689]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.986811</td>\n",
              "      <td>0.539745</td>\n",
              "      <td>[0.9868105563430492, 0.5397451964974905]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1                                    combined  max_index\n",
              "0   0.294665  0.530587    [0.2946650026871097, 0.5305867556052941]          1\n",
              "1   0.191521  0.067900  [0.19152078694749486, 0.06790035819129137]          0\n",
              "2   0.786985  0.656334    [0.7869854599999133, 0.6563335217758555]          0\n",
              "3   0.637521  0.575603     [0.6375208960436358, 0.575602893753034]          0\n",
              "4   0.039063  0.357814  [0.03906291618886648, 0.35781360448354893]          1\n",
              "..       ...       ...                                         ...        ...\n",
              "95  0.913303  0.590220    [0.9133029199647259, 0.5902203718852678]          0\n",
              "96  0.171194  0.714474    [0.17119434728109106, 0.714474477740643]          1\n",
              "97  0.238446  0.921805   [0.23844605886430326, 0.9218051432493948]          1\n",
              "98  0.721274  0.676923    [0.7212738667495618, 0.6769229790876689]          0\n",
              "99  0.986811  0.539745    [0.9868105563430492, 0.5397451964974905]          0\n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
